{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kai Simple Gan 256x256 05_14_2018.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1UWY_1tBSwkNFZn5xs2J_xhVDRS7k_Vtu",
          "timestamp": 1526349382248
        },
        {
          "file_id": "1tSnxp6DVjMt-UiD9PO02rym9BNVdwZFU",
          "timestamp": 1526330784978
        },
        {
          "file_id": "1w7LD4A1-52CnAvPQcgA6RFC7uUy-0SPM",
          "timestamp": 1526327829586
        },
        {
          "file_id": "1Y9KFf2t5Uc2iiAlJUi7MMc6pnQw85GHE",
          "timestamp": 1526324821517
        },
        {
          "file_id": "168zcSbUwjwRky5tzH0NmLplEwywsHdzW",
          "timestamp": 1525899886058
        }
      ]
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "PHaZ42l-gGSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# urban_theory_GAN\n",
        "\n",
        "Hanna Ginzburg & Kai Matheson\n",
        "\n",
        "Code from Mattia Spinelli\n",
        "\n",
        "https://medium.com/@mattiaspinelli/simple-generative-adversarial-network-gans-with-keras-1fe578e44a87\n",
        "\n",
        "https://github.com/daymos/simple_keras_GAN"
      ]
    },
    {
      "metadata": {
        "id": "gvQvRwAA2sVq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from IPython.core.debugger import Tracer\n",
        "\n",
        "\n",
        "#from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "plt.switch_backend('agg')   # allows code to run without a system DISPLAY\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import shutil\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-R_nBrp5ZKTh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKoMjt2AY9mz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('256x256maps.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4WAuxSFrafYg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9HYsbWDZhKUq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mydata = []\n",
        "for filename in os.listdir('256x256maps'):\n",
        "    if filename.endswith(\".png\"): \n",
        "        img = mpimg.imread('256x256maps/' + filename)\n",
        "        img = 255 - cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )\n",
        "        img = misc.imresize(img, (100,100))\n",
        "        img = img.reshape([10000])\n",
        "        mydata.append(img)\n",
        "        continue\n",
        "    else:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OF9sj9yDoHUt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mydata = np.asarray(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9OkONbsHlhsV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mydata.shape\n",
        "#Now each row represents an image and each column represents a pixel that takes a grayscale value between 0 and "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjFiS2qQioHs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(mydata[3].reshape([100,100]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5dTBg86T5_B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIFZ5-umYdO5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.makedirs('images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ii-R4RHdQJka",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class GAN(object):\n",
        "    \"\"\" Generative Adversarial Network class \"\"\"\n",
        "    def __init__(self, width=100, height=100, channels=1):\n",
        "\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.channels = channels\n",
        "\n",
        "        self.shape = (self.width, self.height, self.channels)\n",
        "\n",
        "        self.optimizer = Adam(lr=0.0002, beta_1=0.5, decay=8e-8)\n",
        "\n",
        "        self.G = self.__generator()\n",
        "        self.G.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
        "\n",
        "        self.D = self.__discriminator()\n",
        "        self.D.compile(loss='binary_crossentropy', optimizer=self.optimizer, metrics=['accuracy'])\n",
        "\n",
        "        self.stacked_generator_discriminator = self.__stacked_generator_discriminator()\n",
        "\n",
        "        self.stacked_generator_discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
        "\n",
        "\n",
        "    def __generator(self):\n",
        "        \"\"\" Declare generator \"\"\"\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(256, input_shape=(100,)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(self.width  * self.height * self.channels, activation='tanh'))\n",
        "        model.add(Reshape((self.width, self.height, self.channels)))\n",
        "\n",
        "        return model\n",
        "\n",
        "    def __discriminator(self):\n",
        "        \"\"\" Declare discriminator \"\"\"\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=self.shape))\n",
        "        model.add(Dense((int(self.width * self.height * self.channels)), input_shape=self.shape))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense((int((self.width * self.height * self.channels)/2))))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def __stacked_generator_discriminator(self):\n",
        "\n",
        "        self.D.trainable = False\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(self.G)\n",
        "        model.add(self.D)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, epochs=201, batch = 32, save_interval = 10):\n",
        "\n",
        "        for cnt in range(epochs):\n",
        "\n",
        "            ## train discriminator\n",
        "            random_index = np.random.randint(0, len(X_train) - batch/2)\n",
        "            legit_images = X_train[int(random_index) : int(random_index + batch//2)].reshape(batch//2, self.width, self.height, self.channels)\n",
        "\n",
        "            gen_noise = np.random.normal(0, 1, (batch//2, 100))\n",
        "            syntetic_images = self.G.predict(gen_noise)\n",
        "\n",
        "            x_combined_batch = np.concatenate((legit_images, syntetic_images))\n",
        "            y_combined_batch = np.concatenate((np.ones((batch/2, 1)), np.zeros((batch/2, 1))))\n",
        "\n",
        "            d_loss = self.D.train_on_batch(x_combined_batch, y_combined_batch)\n",
        "\n",
        "\n",
        "            # train generator\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch, 100))\n",
        "            y_mislabled = np.ones((batch, 1))\n",
        "\n",
        "            g_loss = self.stacked_generator_discriminator.train_on_batch(noise, y_mislabled)\n",
        "\n",
        "            print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))\n",
        "\n",
        "            if cnt % save_interval == 0:\n",
        "                self.plot_images(save2file=True, step=cnt)\n",
        "\n",
        "\n",
        "    def plot_images(self, save2file=False, samples=16, step=0):\n",
        "        ''' Plot and generated images '''\n",
        "        filename = \"images/maps_%d.png\" % step\n",
        "        noise = np.random.normal(0, 1, (samples, 100))\n",
        "\n",
        "        images = self.G.predict(noise)\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        \n",
        "        for i in range(images.shape[0]):\n",
        "          image = images[i,:,:,:]\n",
        "          image = np.reshape(image, [self.height, self.width])\n",
        "          plt.imshow(image)\n",
        "        \n",
        "        #for i in range(images.shape[0]):\n",
        "            #plt.subplot(4, 4, i+1)\n",
        "            #plt.subplot(1, 1, i+1)\n",
        "            #image = images[i, :, :, :]\n",
        "            #image = np.reshape(image, [self.height, self.width])\n",
        "            #plt.imshow(image, cmap='gray')\n",
        "            #plt.imshow(image)\n",
        "            #plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save2file:\n",
        "            plt.savefig(filename)\n",
        "            plt.close('all')\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    X_train = (mydata.astype(np.float32) - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "\n",
        "    gan = GAN()\n",
        "    gan.train(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZsS1hC5W_sO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cd images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11mqF4_HYg_r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IqXVqv4_Ymc5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "imgplot = plt.imshow(mpimg.imread('maps_150.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9x3MuDU9wpi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cd ~"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hai9HTNR9gbl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "shutil.make_archive('simple_gan_output', 'zip', 'images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcikiHyV_HtE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files.download('simple_gan_output.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}